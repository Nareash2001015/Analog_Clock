{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPy9YaztCLJxTh4h5I4YkbU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nareash503536/Analog_Clock/blob/main/Experiments/Experiment_Extraction_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fasttext Tamil"
      ],
      "metadata": {
        "id": "DZUgIT1NlCtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ta.300.bin.gz\n",
        "!gunzip cc.ta.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7TPw6TxLIwK",
        "outputId": "660ecec8-34f1-4908-b71d-b730b9eeede7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-27 04:35:47--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ta.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.10, 13.227.219.70, 13.227.219.33, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4510026494 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.ta.300.bin.gz’\n",
            "\n",
            "cc.ta.300.bin.gz    100%[===================>]   4.20G   258MB/s    in 26s     \n",
            "\n",
            "2024-08-27 04:36:14 (165 MB/s) - ‘cc.ta.300.bin.gz’ saved [4510026494/4510026494]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lMiD8Na_NH",
        "outputId": "983077f2-540f-4ebb-809b-6dc490e3a0b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.5-py3-none-any.whl (240 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4246560 sha256=2ee42b86512ec9f722d328e0dbb33221ca5832480adfd38d211ca463c5e13a27\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s4R3P8lZKqUe"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.load_model('/content/cc.ta.300.bin')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "word_embedding_1 = model.get_word_vector('ஓடுகிறான்')\n",
        "word_embedding_2 = model.get_word_vector('ஆடுகிறான்')\n",
        "\n",
        "cosine_similarity([word_embedding_1], [word_embedding_2])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNwLxkloMeLf",
        "outputId": "8880380e-7722-4933-bb3f-b6512924f248"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7045538]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors(\"கிறான்\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8qOm7P2Nc55",
        "outputId": "3fa57983-2d2e-4421-bf6b-b33dca3b710f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7795650959014893, 'க்கிறான்'),\n",
              " (0.7697009444236755, 'கிறான்ற்'),\n",
              " (0.7511381506919861, 'எனகிறான்'),\n",
              " (0.7415184378623962, 'றான்'),\n",
              " (0.7233825325965881, 'கிறானோ'),\n",
              " (0.7140129804611206, 'கிறாள்'),\n",
              " (0.7134764790534973, 'ஓதுகிறான்'),\n",
              " (0.7094616889953613, 'ங்கிறான்'),\n",
              " (0.708574116230011, 'ஏசுகிறான்'),\n",
              " (0.7004019618034363, 'உரறுகிறான்')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding_1 = model.get_word_vector('கின்றான்')\n",
        "model.get_nearest_neighbors(\"ஓடுகிறான்\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGi1Kj6hjDva",
        "outputId": "1722f1be-7fe3-436f-a096-71b9d6c5dc67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8544566035270691, 'ஓடுகின்றான்'),\n",
              " (0.8535919189453125, 'ஓடுகிறானே'),\n",
              " (0.821258544921875, 'ஓடிவருகிறான்'),\n",
              " (0.8042687773704529, 'ஓடிவிடுகிறான்'),\n",
              " (0.7967880964279175, 'ஓடுகிறாள்'),\n",
              " (0.7899633646011353, 'ஒடுகிறான்'),\n",
              " (0.785098671913147, 'உதறுகிறான்'),\n",
              " (0.7802742123603821, 'ஓடியிருக்கிறான்'),\n",
              " (0.7745779156684875, 'ஓடுகிறார்'),\n",
              " (0.7629601955413818, 'ஓடிக்கொண்டிருக்கிறான்')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a function to check if a word matches the desired morphological pattern\n",
        "def is_morphological_match(word, pattern=r\"(.+)கிறான்$\"):\n",
        "    return re.match(pattern, word) is not None\n",
        "\n",
        "# Get nearest neighbors for \"ஓடுகிறான்\"\n",
        "similar_words = model.get_nearest_neighbors(\"ஓடுகிறான்\")\n",
        "\n",
        "# Filter neighbors to include only those that match the morphological pattern\n",
        "morphological_neighbors = [\n",
        "    (similarity, word) for similarity, word in similar_words if is_morphological_match(word)\n",
        "]\n",
        "\n",
        "# Display the filtered results\n",
        "print(\"Morphologically similar words to 'ஓடுகிறான்':\")\n",
        "for similarity, word in morphological_neighbors:\n",
        "    print(f\"{word}: {similarity}\")"
      ],
      "metadata": {
        "id": "nWAf1PT8XVTc",
        "outputId": "90f51619-0523-4b5b-d180-034e58fe95bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morphologically similar words to 'ஓடுகிறான்':\n",
            "ஓடிவருகிறான்: 0.821258544921875\n",
            "ஓடிவிடுகிறான்: 0.8042687773704529\n",
            "ஒடுகிறான்: 0.7899633646011353\n",
            "உதறுகிறான்: 0.785098671913147\n",
            "ஓடியிருக்கிறான்: 0.7802742123603821\n",
            "ஓடிக்கொண்டிருக்கிறான்: 0.7629601955413818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = model.get_nearest_neighbors(\"ஓடுகிறான்\")"
      ],
      "metadata": {
        "id": "VZNEnVHHlWVl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Target word embedding\n",
        "target_word = 'நடக்கிறான்'\n",
        "target_word_embedding = model.get_word_vector('நடக்கிறான்')\n",
        "\n",
        "# Corpus of words to compare against\n",
        "corpus_words = ['ஆடுகிறான்', 'ஓடுகின்றான்', 'விடுகிறான்', 'படிக்கிறான்']  # Example words\n",
        "similar_words = []\n",
        "\n",
        "# Calculate similarity for each word in the corpus\n",
        "for word in corpus_words:\n",
        "    word_embedding = model.get_word_vector(word)\n",
        "    similarity = cosine_similarity([target_word_embedding], [word_embedding])[0][0]\n",
        "    print(f\"Similarity between '{target_word}' and '{word}': {similarity}\")\n",
        "\n",
        "    # Define a similarity threshold, e.g., 0.8\n",
        "    if similarity > 0.7:\n",
        "        similar_words.append((word, similarity))\n",
        "\n",
        "# Output the words with similar grammatical features\n",
        "print(\"Words with similar grammatical features:\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"Word: {word}, Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBJjJtAJhX0F",
        "outputId": "aa0b1d93-6ee5-4652-eda8-11703f89c6f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'நடக்கிறான்' and 'ஆடுகிறான்': 0.6781009435653687\n",
            "Similarity between 'நடக்கிறான்' and 'ஓடுகின்றான்': 0.6190581321716309\n",
            "Similarity between 'நடக்கிறான்' and 'விடுகிறான்': 0.6133695840835571\n",
            "Similarity between 'நடக்கிறான்' and 'படிக்கிறான்': 0.5596916675567627\n",
            "Words with similar grammatical features:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors(\"நேசிக்கிறேன்\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1a6uPlKjwX_",
        "outputId": "f5cfbc0a-ad09-499b-8140-c4d33f436a70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.86745285987854, 'நேசிக்கின்றேன்'),\n",
              " (0.8491986393928528, 'நேசிக்கிறேன்21'),\n",
              " (0.8309656381607056, 'நேசிக்கிறேனோ'),\n",
              " (0.7989344596862793, 'நேசிக்கிறீர்கள்'),\n",
              " (0.7879984974861145, 'நேசிப்பேன்'),\n",
              " (0.7860887050628662, 'நேசிக்கிறது'),\n",
              " (0.7829373478889465, 'நேசித்திருக்கிறேன்'),\n",
              " (0.77989661693573, 'நேசிக்கிறாய்'),\n",
              " (0.7636066675186157, 'நேசித்தேன்'),\n",
              " (0.7626577019691467, 'நேசிக்கிறோம்')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Example morphological data for training\n",
        "corpus = [\"ஆடுகிறான்\", \"பாடுகிறான்\", \"ஆடு\", \"ஓடுகிறான்\", \"ஓடுகின்றான்\"]\n",
        "morph_analysis = {\n",
        "    \"ஆடுகிறான்\": (\"PRESENT\", \"3rd\", \"singular\", \"male\"),\n",
        "    \"பாடுகிறான்\": (\"PRESENT\", \"3rd\", \"singular\", \"male\"),\n",
        "    \"ஆடு\": (\"IMPERATIVE\", \"NA\", \"singular\", \"NA\"),\n",
        "    \"ஓடுகிறான்\": (\"PRESENT\", \"3rd\", \"singular\", \"male\"),\n",
        "    \"ஓடுகின்றான்\": (\"PRESENT\", \"3rd\", \"singular\", \"male\")\n",
        "}\n",
        "\n",
        "# Get FastText embeddings\n",
        "embeddings = np.array([model.get_word_vector(word) for word in corpus])\n",
        "\n",
        "# Prepare labels for each morphological feature\n",
        "tense_labels  = [morph_analysis[word][0] for word in corpus]\n",
        "person_labels = [morph_analysis[word][1] for word in corpus]\n",
        "number_labels = [morph_analysis[word][2] for word in corpus]\n",
        "gender_labels = [morph_analysis[word][3] for word in corpus]\n",
        "\n",
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoders = {}\n",
        "encoded_labels = {}\n",
        "\n",
        "for feature_name, labels in zip([\"tense\", \"person\", \"number\", \"gender\"],\n",
        "                                [tense_labels, person_labels, number_labels, gender_labels]):\n",
        "    le = LabelEncoder()\n",
        "    encoded_labels[feature_name] = le.fit_transform(labels)\n",
        "    label_encoders[feature_name] = le\n",
        "\n",
        "# Train classifiers for each feature\n",
        "classifiers = {}\n",
        "for feature_name in encoded_labels.keys():\n",
        "    X_train, X_test, y_train, y_test = train_test_split(embeddings, encoded_labels[feature_name], test_size=0.2)\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    classifiers[feature_name] = clf\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f\"Classification report for {feature_name}:\\n\", classification_report(y_test, y_pred, target_names=label_encoders[feature_name].classes_))\n",
        "\n",
        "# Function to predict morphological features for a new word\n",
        "def predict_morph_features(word):\n",
        "    embedding = model.get_word_vector(word)\n",
        "    predictions = {}\n",
        "    for feature_name, clf in classifiers.items():\n",
        "        pred = clf.predict([embedding])[0]\n",
        "        predictions[feature_name] = label_encoders[feature_name].inverse_transform([pred])[0]\n",
        "    return predictions\n",
        "\n",
        "# Test with an unseen word\n",
        "new_word = \"ஓடுகிறான்\"\n",
        "predicted_features = predict_morph_features(new_word)\n",
        "print(f\"Predicted morphological features for {new_word}: {predicted_features}\")\n",
        "\n",
        "# Expected output: {'tense': 'PRESENT', 'person': '3rd', 'number': 'singular', 'gender': 'male'}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "ISIuXYhl8fN4",
        "outputId": "bbef2b50-00bd-4c13-b8c8-a5762389b84d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-41ba666c48b4>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Classification report for {feature_name}:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Function to predict morphological features for a new word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2565\u001b[0m             )\n\u001b[1;32m   2566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2567\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2568\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2569\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec Tamil"
      ],
      "metadata": {
        "id": "1uhHFeoYlTMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/w2v_cc_300d_ta_3.4.1_3.0_1647462039197.zip\n"
      ],
      "metadata": {
        "id": "kxftaT9Nkz5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip w2v_cc_300d_ta_3.4.1_3.0_1647462039197.zip.1"
      ],
      "metadata": {
        "id": "m9kSC0ELlXVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlu\n",
        "!pip install pyspark==3.0.1\n",
        "!pip install johnsnowlabs"
      ],
      "metadata": {
        "id": "hzNaR8RQndwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nlu\n",
        "spark_model = nlu.load(\"ta.embed.w2v_cc_300d\")"
      ],
      "metadata": {
        "id": "SmS6hGTkmUL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_model.predict(\"\"\"நான் தீப்பொறி NLP ஐ நேசிக்கிறேன்\"\"\")"
      ],
      "metadata": {
        "id": "5smXVUNHnnZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install augly[text]"
      ],
      "metadata": {
        "id": "p_ds0G8WXn99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import augly.text as txtaugs\n",
        "from augly.text import replace_text\n",
        "\n",
        "texts = [\"hello world\", \"bye planet\"]\n",
        "transform = replace_text(texts)\n",
        "aug_texts = transform(texts)\n",
        "print(aug_texts)"
      ],
      "metadata": {
        "id": "Fpc_Dxjq6kjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TokenfreeEMNLPSubmission/mbert-base-finetuned-pos-ud-tamil-ttb\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"TokenfreeEMNLPSubmission/mbert-base-finetuned-pos-ud-tamil-ttb\")"
      ],
      "metadata": {
        "id": "Nvpqu7NEW9Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = tokenizer(\n",
        "    \"சென்னை அருகே ஸ்ரீ பெரும்புதூரில் கிரீன் பீல்டு (நவீன) விமான நிலையத்துக்குக்கான நிலம் யாருக்கும் பாதிப்பு இல்லாத வகையில் எடுக்கப் படும் என்று முதல்வர் கருணாநிதி உறுதியளித்துள்ளார்.\", add_special_tokens=False, return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "predicted_token_class_ids = logits.argmax(-1)\n",
        "print(inputs.tokens())\n",
        "\n",
        "# Note that tokens are classified rather then input words which means that\n",
        "# there might be more predicted token classes than words.\n",
        "# Multiple token classes might account for the same word\n",
        "predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n",
        "predicted_tokens_classes\n",
        "\n",
        "# labels = predicted_token_class_ids\n",
        "# loss = model(**inputs, labels=labels).loss\n",
        "# round(loss.item(), 2)"
      ],
      "metadata": {
        "id": "fMna7ZY0hJzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMnKwBGPi08o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}